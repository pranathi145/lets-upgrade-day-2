{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final amazon review sentiment analysis.ipynb",
      "provenance": [],
      "mount_file_id": "1IFqljjmaGkn8UeFkYG2xxey7JTppoKf3",
      "authorship_tag": "ABX9TyMZ8ZWmwcNsU1lKy89yChYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranathi145/lets-upgrade-day-2/blob/main/Final_amazon_review_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx-BTENlfK-D",
        "outputId": "cba83ab4-0310-4995-cd3f-4746e2561703"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ks5Xk8evfQZT"
      },
      "source": [
        "import bz2\n",
        "import numpy as np\n",
        "def get_labels_and_texts(file):\n",
        "    labels = []\n",
        "    texts = []\n",
        "    for line in bz2.BZ2File(file):\n",
        "        x = line.decode(\"utf-8\")[0:5000]\n",
        "        labels.append(int(x[9]) - 1)\n",
        "        texts.append(x[10:].strip())\n",
        "    return np.array(labels), texts\n",
        "train_labels, train_texts = get_labels_and_texts('/content/drive/MyDrive/train.ft.txt.bz2')\n",
        "test_labels, test_texts = get_labels_and_texts('/content/drive/MyDrive/test.ft.txt.bz2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vm2m0Yj-fw05"
      },
      "source": [
        "import re\n",
        "NON_ALPHANUM = re.compile(r'[\\W]')\n",
        "NON_ASCII = re.compile(r'[^a-z0-1\\s]')\n",
        "def normalize_texts(texts):\n",
        "    normalized_texts = []\n",
        "    for text in texts:\n",
        "        lower = text.lower()\n",
        "        no_punctuation = NON_ALPHANUM.sub(r' ', lower)\n",
        "        no_non_ascii = NON_ASCII.sub(r'', no_punctuation)\n",
        "        normalized_texts.append(no_non_ascii)\n",
        "    return normalized_texts\n",
        "        \n",
        "train_texts = normalize_texts(train_texts)\n",
        "test_texts = normalize_texts(test_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cb3TBwu5f6f6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_texts, train_labels, random_state=57643892, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XVJ97Fl_gchc"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bRTQqbdef7Sx"
      },
      "source": [
        "MAX_FEATURES = 12000\n",
        "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_texts = tokenizer.texts_to_sequences(train_texts)\n",
        "val_texts = tokenizer.texts_to_sequences(val_texts)\n",
        "test_texts = tokenizer.texts_to_sequences(test_texts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qgR4XD4ikcLt"
      },
      "source": [
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from tensorflow.python.keras import models, layers, optimizers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jR6z42STf-0_"
      },
      "source": [
        "MAX_LENGTH = max(len(train_ex) for train_ex in train_texts)\n",
        "train_texts = pad_sequences(train_texts, maxlen=MAX_LENGTH)\n",
        "val_texts = pad_sequences(val_texts, maxlen=MAX_LENGTH)\n",
        "test_texts = pad_sequences(test_texts, maxlen=MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IjIIqNrngEFs"
      },
      "source": [
        "def build_model():\n",
        "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
        "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
        "    x = layers.Conv1D(64, 3, activation='relu')(embedded)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool1D(3)(x)\n",
        "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool1D(5)(x)\n",
        "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
        "    x = layers.GlobalMaxPool1D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(100, activation='relu')(x)\n",
        "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = models.Model(inputs=sequences, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer='rmsprop',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['binary_accuracy']\n",
        "    )\n",
        "    return model\n",
        "    \n",
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTowkc6igOuo",
        "outputId": "e9d175b2-7392-4ccc-f944-a713fe2d0328"
      },
      "source": [
        "model.fit(\n",
        "    train_texts, \n",
        "    train_labels, \n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    validation_data=(val_texts, val_labels), )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "22500/22500 [==============================] - 4012s 178ms/step - loss: 0.1434 - binary_accuracy: 0.9474 - val_loss: 0.1427 - val_binary_accuracy: 0.9479\n",
            "Epoch 2/2\n",
            "22500/22500 [==============================] - 4030s 179ms/step - loss: 0.1386 - binary_accuracy: 0.9497 - val_loss: 0.1455 - val_binary_accuracy: 0.9479\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7f041a4990>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWiqB3QLmBlC"
      },
      "source": [
        "preds = model.predict(test_texts)\n",
        "print('Accuracy score: {:0.4}'.format(accuracy_score(test_labels, 1 * (preds > 0.5))))\n",
        "print('F1 score: {:0.4}'.format(f1_score(test_labels, 1 * (preds > 0.5))))\n",
        "print('ROC AUC score: {:0.4}'.format(roc_auc_score(test_labels, preds)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}